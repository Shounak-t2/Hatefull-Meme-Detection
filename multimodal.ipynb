{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '/model-checkpoint2'\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "path=\"/hateful_memes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_json('dev_seen.jsonl',lines=True)\n",
    "test = pd.read_json('test_seen.jsonl',lines=True)\n",
    "train = pd.read_json('train.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.label.value_counts())\n",
    "print(val.label.value_counts())\n",
    "print(test.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_len'] = train['text'].str.split().str.len()\n",
    "train['idx'] = train['id'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['idx'] = val['id'].astype(str).str.zfill(5)\n",
    "test['idx'] = test['id'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "y_train = train[\"label\"].values.tolist()\n",
    "class_weights = class_weight.compute_class_weight(class_weight ='balanced',\n",
    "                                                 classes = np.unique(y_train),\n",
    "                                                 y = y_train)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_metrics, load_metric\n",
    "metrics_list = list_metrics()\n",
    "\n",
    "acc_metric = load_metric('accuracy')\n",
    "f1_metric = load_metric('f1')\n",
    "precision_metric = load_metric('precision')\n",
    "recall_metric = load_metric('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, VisualBertForPreTraining, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "feature_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HatefulMemesData(Dataset):\n",
    "    def __init__(self, df, tokenizer, sequence_length, \n",
    "                 print_text=False):         \n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.print_text = print_text\n",
    "\n",
    "        texts = df[\"text\"].values.tolist()\n",
    "        labels = df[\"label\"].values.tolist()\n",
    "        images = df[\"img\"].values.tolist()\n",
    "        ids =  df[\"idx\"].values.tolist()\n",
    "\n",
    "        self.dataset = []\n",
    "        for i, inp in enumerate(texts):\n",
    "            self.dataset.append({\"text\": inp, \"label\": labels[i], 'idx': ids[i], 'image': images[i]})\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "   \n",
    "        idx = example['idx']\n",
    "        idx = [idx] if isinstance(idx, str) else idx\n",
    "        # encoded_dict = tokenizer.batch_encode_plus(example['text'], padding='max_length', max_length=max_len, truncation=True, return_tensors='pt')\n",
    "        encoded_dict = tokenizer(example['text'], padding='max_length', max_length=self.sequence_length, truncation=True, return_tensors='pt')\n",
    "        tokens = encoded_dict['input_ids']\n",
    "        token_type_ids = encoded_dict['token_type_ids']\n",
    "        attn_mask = encoded_dict['attention_mask']\n",
    "        \n",
    "        targets = torch.tensor(example['label']).type(torch.int64)\n",
    "\n",
    "        ## Get Visual Embeddings\n",
    "        try:\n",
    "            img = example['image']\n",
    "            img = Image.open(os.path.join('hateful_memes', img))\n",
    "            img = np.array(img)\n",
    "            img = img[...,:3]\n",
    "            inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "            outputs = feature_model(**inputs.to('cuda'))\n",
    "            visual_embeds = outputs.last_hidden_state\n",
    "            visual_embeds = visual_embeds.cpu()\n",
    "        except:\n",
    "            # print(\"Error with Id: \", idx)\n",
    "            visual_embeds = np.zeros(shape=(197, 768), dtype=float)\n",
    "            print(\"images not found\")\n",
    "        # visual_embeds = visual_embeds.repeat(1,1,2)\n",
    "\n",
    "        visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.int64)\n",
    "        visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.int64)\n",
    "\n",
    "        inputs={\"input_ids\": tokens.squeeze(),\n",
    "            \"attention_mask\": attn_mask.squeeze(),\n",
    "            \"token_type_ids\": token_type_ids.squeeze(),\n",
    "            \"visual_embeds\": visual_embeds.squeeze(),\n",
    "            \"visual_token_type_ids\": visual_token_type_ids.squeeze(),\n",
    "            \"visual_attention_mask\": visual_attention_mask.squeeze(),\n",
    "            \"label\": targets.squeeze()\n",
    "        }\n",
    "        \n",
    "        return inputs\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenize_data(self.dataset[index])\n",
    "        \n",
    "        if self.print_text:\n",
    "            for k in inputs.keys():\n",
    "                print(k, inputs[k].shape, inputs[k].dtype)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HatefulMemesData(val, tokenizer, 500, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, VisualBertModel, TrainingArguments, Trainer, VisualBertConfig\n",
    "configuration = VisualBertConfig.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre',\n",
    "                                                hidden_dropout_prob=0.3, attention_probs_dropout_prob=0.3)\n",
    "model = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre', config=configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1['input_ids'].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from datasets import load_metric\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    VisualBertModel,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import logging\n",
    "import argparse\n",
    "import time\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "from pathlib import Path\n",
    "from string import punctuation\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.77510622, 1.40873991]\n",
    "wt_tensor = torch.FloatTensor(weights).cuda()\n",
    "print(wt_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualBERTClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(VisualBERTClassifier, self).__init__()\n",
    "        configuration = VisualBertConfig.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre',\n",
    "                                                hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\n",
    "        self.visualbert = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre', config=configuration)\n",
    "        self.embed_cls = nn.Linear(768, 1024)\n",
    "        # self.visualbert = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre')\n",
    "        self.num_labels = 2\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.cls=  nn.Linear(768, self.num_labels)\n",
    "        self.weight = torch.FloatTensor([class_weights]) #torch.FloatTensor([0.77510622, 1.40873991]),\n",
    "\n",
    "        nSamples = [5178, 2849]\n",
    "        normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "        self.loss_fct = CrossEntropyLoss(weight=torch.FloatTensor(normedWeights))\n",
    "        \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, visual_embeds, visual_attention_mask,\n",
    "                visual_token_type_ids, labels):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        visual_embeds_cls = self.embed_cls(visual_embeds)\n",
    "        outputs = self.visualbert(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                visual_embeds=visual_embeds_cls,\n",
    "                visual_attention_mask=visual_attention_mask,\n",
    "                visual_token_type_ids=visual_token_type_ids,\n",
    "            )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.cls(pooled_output)\n",
    "        reshaped_logits = logits.view(-1, self.num_labels)\n",
    "\n",
    "        loss = self.loss_fct(reshaped_logits, labels.view(-1))\n",
    "      \n",
    "        return loss, reshaped_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisualBERTClassifier().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "batch_size = 85\n",
    "seq_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisualBERTClassifier()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"auroc\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"model-checkpoint2\",\n",
    "    seed = 420, \n",
    "    evaluation_strategy = \"steps\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs= 10,\n",
    "    weight_decay=0.05,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    eval_steps = 50,\n",
    "    save_steps = 500,\n",
    "    fp16 = False,\n",
    "    gradient_accumulation_steps = 2\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels)\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels)\n",
    "    auc_score = roc_auc_score(labels, predictions)\n",
    "    return {\"accuracy\": acc['accuracy'], \"auroc\": auc_score,'f1':f1['f1'],'precision':precision['precision'],'recall':recall['recall']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset = HatefulMemesData(train,tokenizer=tokenizer, sequence_length=seq_len),\n",
    "    # eval_dataset =  HatefulMemesData(val,tokenizer=tokenizer, sequence_length=seq_len),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_from ='/model-checkpoint1/checkpoint-1000'\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()\n",
    "trainer.save_model('VisualBERT_classification_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
